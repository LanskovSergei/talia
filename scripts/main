import os
from fastapi import FastAPI, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from llama_index import StorageContext, load_index_from_storage
from openai import OpenAI
from talia_assistant import generate_talia_response

# === –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–ª—é—á OpenAI ===
os.environ["OPENAI_API_KEY"] = ""
client = OpenAI()

# === –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω–¥–µ–∫—Å –∏–∑ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–π –±–∞–∑—ã ===
print("üì¶ –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω–¥–µ–∫—Å –∏–∑ ./storage ...")
storage_context = StorageContext.from_defaults(persist_dir="./storage")
index = load_index_from_storage(storage_context)
query_engine = index.as_query_engine()

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI ===
app = FastAPI()

# === –†–∞–∑—Ä–µ—à–∞–µ–º CORS –¥–ª—è n8n, –±—Ä–∞—É–∑–µ—Ä–∞ –∏ —Ç.–¥. ===
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# === –û–±—Ä–∞–±–æ—Ç—á–∏–∫ GET /ask ===
@app.get("/ask")
def ask(query: str = Query(..., description="–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")):
    print(f"üß† –ó–∞–ø—Ä–æ—Å –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {query}")
    base_response = query_engine.query(query)
    raw_text = str(base_response)

    gpt_response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {
                "role": "system",
                "content": (
                    "–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º –æ–±—â–µ–Ω–∏—è.\n"
                    "–ù–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –æ–ø—Ä–µ–¥–µ–ª–∏, –∫–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–µ–±—è –≤–µ—Å—Ç–∏ –≤ —ç—Ç–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏.\n"
                    "–î–∞–π –ø–æ–¥—Ä–æ–±–Ω—É—é, –Ω–æ —Å–∂–∞—Ç—É—é –≤—ã–∂–∏–º–∫—É: 2‚Äì4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, —Ç–æ–ª—å–∫–æ —Å—É—Ç—å.\n"
                    "–ù–µ —Ü–∏—Ç–∏—Ä—É–π –Ω–∞–ø—Ä—è–º—É—é, –Ω–µ —É–ø–æ–º–∏–Ω–∞–π –∏—Å—Ç–æ—á–Ω–∏–∫–∏. –ü—Ä–æ—Å—Ç–æ –æ–±—ä—è—Å–Ω–∏ –ø–æ–≤–µ–¥–µ–Ω–∏–µ, —Ç–æ–Ω –æ–±—â–µ–Ω–∏—è –∏ —á–µ–≥–æ –∏–∑–±–µ–≥–∞—Ç—å."
                )
            },
            {"role": "user", "content": raw_text}
        ]
    )

    final_summary = gpt_response.choices[0].message.content.strip()
    return {"answer": final_summary}

# === –ù–æ–≤—ã–π –º–∞—Ä—à—Ä—É—Ç POST /talia (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π) ===
class TaliaRequest(BaseModel):
    content: str
    thread_id: str
    user_id: str
    system_context: str

@app.post("/talia")
def ask_talia(data: TaliaRequest):
    try:
        print(f"üß† TALIA: —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {data.user_id} ‚Äî {data.content}")
        result = generate_talia_response(
            content=data.content,
            thread_id=data.thread_id,
            user_id=data.user_id,
            system_context=data.system_context
        )
        return result
    except Exception as e:
        return {"error": str(e)}


